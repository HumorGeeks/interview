# CPU 三级缓存架构

## CPU 读取存储器数据过程

1. CPU要取寄存器X的值，只需要一步：直接读取
2. PU要取L1 cache的某个值，需要1-3步（或者更多）：把cache行锁住，把某个数据拿来，解锁，如果没锁住就慢了
3. CPU要取L2 cache的某个值，先要到L1 cache里取，L1当中不存在，在L2里，L2开始加锁，加锁以后，把L2里的数据复制到L1，再执行读L1的过程，上面的3步，再解锁
4. CPU取L3 cache的也是一样，只不过先由L3复制到L2，从L2复制到L1，从L1到CPU
5. CPU取内存则最复杂：通知内存控制器占用总线带宽，通知内存加锁，发起内存读请求，等待回应，回应数据保存到L3（如果没有就到L2），再从L3/2到L1，再从L1到CPU，之后解除总线锁定

## 时间局部性

> 如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。比如循环、递归、方法的反复调用等

## 空间局部性

> 如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。比如顺序执行的代码、连续创建的两个对象、数组等

## 带有高速缓存的CPU执行计算的流程

1. 程序以及数据被加载到主内存
2. 指令和数据被加载到CPU的高速缓存
3. CPU执行指令，把结果写到高速缓存
4. 高速缓存中的数据写回主内存

## CPU运行安全等级

ring0（内核态）：可以运行所有操作；操作系统内部内部程序指令通常运行在ring0级别（修改内存；mysql 数据（undo和redo）刷盘；）

ring1

ring2

ring3：（用户态）操作系统以外的第三方程序运行在ring3级别第三方程序如果要调用操作,系统内部函数功能，由于运行安全级别不够,必须切换CPU运行状态，从ring3切换到ring0,然后执行系统函数，JVM创建线程，线程阻塞唤醒是重型操作了，因为CPU要切换运行状态

PS：进程和线程对应有两个堆栈；一个在用户空间里边；一个在内核空间里边

## 线程模型

> CPU调度的基本单位是线程，也划分为

用户线程模型：线程创建、销毁、调度由用户程序实现

线程阻塞不会引起进程阻塞。在多处理器系统上，多线程在多处理器上并行运行。线程的创建、调度和管
理由内核完成，效率比ULT要慢，比进程操作快

内核线程模型：线程创建、销毁、调度由操作系统完成

## 进程与线程

进程：现代操作系统在运行一个程序时，会为其创建一个进程；例如，启动一个Java程序，操作系统就会创建一个Java进程。进程是OS(操作系统)资源分配的最小单位

线程：线程是OS(操作系统)调度CPU的最小单元，也叫轻量级进程（Light Weight Process），在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量

## 线程上下文切换

> CPU切换前把当前任务的状态保存下来，以便下次切换回这个任务时可以再次加载这个任务的状态，然后加载下一任务的状态并执行。任务的状态保存及再加载, 这段过程就叫做上下文切换

## 线程上下文切换问题

- **直接消耗**：指的是CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉
- **间接消耗**：指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小

## 虚拟机指令架构

1. 栈指令集架构
   1. 设计和实现更简单,适用于资源受限的系统;
   2. 避开了寄存器的分配难题:使用零地址指令方式分配;
   3. 指令流中的指令大部分是零地址指令,其执行过程依赖与操作栈,指令集更小,编译器容易实现;
   4. 不需要硬件支持,可移植性更好,更好实现跨平台
2. 寄存器指令集架构
   1. 典型的应用是x86的二进制指令集:比如传统的PC以及Android的Davlik虚拟机。
   2. 指令集架构则完全依赖硬件,可移植性差。
   3. 性能优秀和执行更高效。
   4. 花费更少的指令去完成一项操作。
   5. 在大部分情况下,基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主,而基于栈式架构的指令集却是以零地址指令为主。Java符合典型的栈指令集架构特征，像Python、Go都属于这种架构。

# JMM

主内存

主要存储的是Java实例对象，所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量(也称局部变量)，当然也包括了共享的类信息、常量、静态变量。由于是共享数据区域，多条线程对同一个变量进行访问可能会发生线程安全问题

工作内存

存储当前方法的所有本地变量信息(工作内存中存储着主内存中的变量副本拷贝)，每个线程只能访问自己的工作内存，即线程中的本地变量对其它线程是不可见的，就算是两个线程执行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，当然也包括了字节码行号指示器、相关Native方法的信息

## 数据同步八大原子操作

1. lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态
2. unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
3. read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
4. load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中
5. use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎
6. assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量
7. store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作
8. write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中

## 并发编程特性

1. 可见性（volatile）不保证原子性

   - 代码层面：共享变量改变后其他线程**立刻**感知到修改
   - 字节码层面：多一个访问标志ACC_VOLATILE
   - 缓存一致性协议

2. 原子性：原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响（synchronized和Lock）

3. 有序性：

   > 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述volatile关键字）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性
